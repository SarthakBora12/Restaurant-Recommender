{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d6f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /Users/sarthak/opt/anaconda3/lib/python3.9/site-packages (from scikit-surprise) (1.24.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/sarthak/opt/anaconda3/lib/python3.9/site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/sarthak/opt/anaconda3/lib/python3.9/site-packages (from scikit-surprise) (1.9.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp39-cp39-macosx_10_9_x86_64.whl size=507971 sha256=8e160d95a2428f63adb109a3741b542997f34c9ce68ce70b12768f82fd817514\n",
      "  Stored in directory: /Users/sarthak/Library/Caches/pip/wheels/42/41/d3/a56ae864ad22cc6583ec9312be43fbc611c87e53dc49aac953\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fdadb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pickle\n",
    "\n",
    "# Load the filtered reviews data\n",
    "reviews_df = pd.read_csv(\"filtered_reviews_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5219450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 1.2172\n",
      "Model RMSE: 1.2172\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare data for collaborative filtering using Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(reviews_df[['user_id', 'business_id', 'stars']], reader)\n",
    "\n",
    "# Step 2: Train-test split\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train SVD model\n",
    "svd = SVD(n_factors=100, biased=True, verbose=True)\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Step 4: Evaluate model\n",
    "predictions = svd.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"Model RMSE: {rmse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbac433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Recommendations for User 8g_iMtfSiwikVnbP2etR0A:\n",
      "Milktooth - Predicted Rating: 5.00\n",
      "Tavern - Predicted Rating: 5.00\n",
      "Chase's Hop Shop - Predicted Rating: 5.00\n",
      "Angelina's - Predicted Rating: 5.00\n",
      "Sips Specialty Coffee House - Predicted Rating: 5.00\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Save model\n",
    "with open(\"svd_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svd, f)\n",
    "\n",
    "# Step 6: Create prediction function\n",
    "def recommend_for_user(user_id, top_n=5):\n",
    "    unique_businesses = reviews_df['business_id'].unique()\n",
    "    reviewed = set(reviews_df[reviews_df['user_id'] == user_id]['business_id'])\n",
    "    to_predict = [bid for bid in unique_businesses if bid not in reviewed]\n",
    "    \n",
    "    predictions = [\n",
    "        (bid, svd.predict(user_id, bid).est)\n",
    "        for bid in to_predict\n",
    "    ]\n",
    "    top_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Map business IDs back to names\n",
    "    business_df = pd.read_csv(\"filtered_business_data.csv\")\n",
    "    id_to_name = dict(zip(business_df['business_id'], business_df['name']))\n",
    "    recommendations = [(id_to_name.get(bid, \"Unknown\"), score) for bid, score in top_predictions]\n",
    "\n",
    "    print(f\"\\nTop {top_n} Recommendations for User {user_id}:\")\n",
    "    for name, score in recommendations:\n",
    "        print(f\"{name} - Predicted Rating: {score:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "example_user = reviews_df['user_id'].iloc[0]\n",
    "recommend_for_user(example_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2739bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6761f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d78dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436aed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pickle\n",
    "\n",
    "# Load filtered reviews and business data\n",
    "reviews_df = pd.read_csv(\"filtered_reviews_data.csv\")\n",
    "business_df = pd.read_csv(\"filtered_business_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac75fa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 1.2170\n",
      "Model RMSE: 1.2170\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare data for collaborative filtering using Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(reviews_df[['user_id', 'business_id', 'stars']], reader)\n",
    "\n",
    "# Step 2: Train-test split\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train SVD model\n",
    "svd = SVD(n_factors=100, biased=True, verbose=True)\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Step 4: Evaluate model\n",
    "predictions = svd.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"Model RMSE: {rmse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c26c5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: vader_sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lq/y329zs_j3w7263ksk8s4c__m0000gn/T/ipykernel_1302/299978186.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 6: Precompute average sentiment per business\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msentiment_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vader_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1949\u001b[0m                 \u001b[0;34m\"Use a list instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m             )\n\u001b[0;32m-> 1951\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: vader_sentiment'"
     ]
    }
   ],
   "source": [
    "# Step 5: Save model\n",
    "with open(\"svd_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svd, f)\n",
    "\n",
    "# Step 6: Precompute average sentiment per business\n",
    "sentiment_avg = reviews_df.groupby('business_id')['vader_sentiment'].mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Enhanced recommendation function\n",
    "def recommend_for_user(user_id, top_n=5, city=None):\n",
    "    user_reviews = reviews_df[reviews_df['user_id'] == user_id]\n",
    "    reviewed = set(user_reviews['business_id'])\n",
    "\n",
    "    # Filter candidate businesses\n",
    "    candidate_df = business_df[~business_df['business_id'].isin(reviewed)]\n",
    "    if city:\n",
    "        candidate_df = candidate_df[candidate_df['city'].str.lower() == city.lower()]\n",
    "\n",
    "    # Predict and rank\n",
    "    recommendations = []\n",
    "    for _, row in candidate_df.iterrows():\n",
    "        bid = row['business_id']\n",
    "        name = row['name']\n",
    "        pred_rating = svd.predict(user_id, bid).est\n",
    "        sentiment = sentiment_avg.get(bid, 0.0)\n",
    "        final_score = 0.6 * pred_rating + 0.4 * sentiment  # Weighted combination\n",
    "        recommendations.append((name, pred_rating, sentiment, final_score))\n",
    "\n",
    "    top_recs = sorted(recommendations, key=lambda x: x[3], reverse=True)[:top_n]\n",
    "\n",
    "    print(f\"\\nTop {top_n} Recommendations for User {user_id}{' in ' + city if city else ''}:\")\n",
    "    for name, rating, sentiment, score in top_recs:\n",
    "        print(f\"{name} | Predicted Rating: {rating:.2f} | Sentiment: {sentiment:.2f} | Final Score: {score:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "example_user = reviews_df['user_id'].iloc[0]\n",
    "recommend_for_user(example_user, top_n=5, city='Tucson')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
